A Multi-Page Streamlit Demo App for Teaching NLP & Machine Translation

Executive Summary

This white paper describes the architecture, requirements, and implementation outline for a simple, interactive Streamlit application designed to educate a non-technical audience on key concepts in Natural Language Processing (NLP) and Machine Translation (MT).

The app demonstrates:
	â€¢	Tokenization
	â€¢	Embeddings & Vector Similarity
	â€¢	Real-time Machine Translation
	â€¢	Context Effects in Transformers

Each concept is presented as a separate page, with step-by-step UI controls so users can observe how models convert human language into numbers, vectors, and translated outputs.

â¸»

ğŸ¯ Objectives
	1.	Deliver a simple, safe, stable demo environment suitable for live webinars.
	2.	Provide hands-on, visual, sequential demonstrations that show how NLP works.
	3.	Keep technical complexity hidden while allowing users to â€œpeekâ€ behind the curtain.
	4.	Ensure code is minimal, dependencies light, and API usage predictable.

â¸»

ğŸ—ï¸ High-Level Architecture

Streamlit App
â”‚
â”œâ”€â”€ Home / Overview Page
â”‚
â”œâ”€â”€ Tokenization Playground
â”‚     - Subword tokenization
â”‚     - Token IDs & visual chips
â”‚
â”œâ”€â”€ Embedding Similarity Explorer
â”‚     - Vector generation
â”‚     - Cosine similarity
â”‚
â”œâ”€â”€ Translation Sandbox
â”‚     - Basic translation
â”‚     - Context dependency
â”‚
â””â”€â”€ Word Order & Transformer Behavior Demo
      - Reordering sentences
      - Observing translation drift

All NLP and MT logic is handled via:
	â€¢	OpenAI Models (recommended for simplicity/stability)
	â€¢	Or HuggingFace Transformers (optional alternative)

â¸»

ğŸ“¦ Tools, Libraries & Models

Python Libraries

Library	Purpose
streamlit	UI framework
openai	Embeddings, translation, tokenization
numpy	Cosine similarity computation
tiktoken	Local GPT-style tokenization
plotly (optional)	Fancy visualization of vector similarity


â¸»

Models Used

1. Tokenization
	â€¢	tiktoken (local)
	â€¢	Fast, no API calls
	â€¢	Matches GPT tokenizer behavior

2. Embeddings
	â€¢	text-embedding-3-small (OpenAI)
	â€¢	1536-dimensional embedding
	â€¢	Low cost, fast
	â€¢	Great for semantic similarity demos

3. Translation
	â€¢	gpt-4.1-mini or gpt-4o-mini
	â€¢	Multilingual
	â€¢	Fast enough for live demos
	â€¢	Handles ambiguity & context well

4. Context/Transformer Behavior
	â€¢	Same translation models above
	â€¢	Demonstrates attention implicitly via improved contextual translation

â¸»

âš™ï¸ Installation Requirements

Python Version

Python 3.9+

Install Dependencies

pip install streamlit openai numpy tiktoken plotly

Environment Variables

Set the OpenAI-compatible Bedrock endpoint along with the model names you want to demo:

```
export OPENAI_API_KEY="your-key"
export OPENAI_API_BASE="https://bedrock.us-east-1.amazonaws.com/openai"
export OPENAI_EMBEDDING_MODEL="amazon.titan-embed-text"
export OPENAI_TRANSLATION_MODEL="amazon.titan-translate"
```


â¸»

ğŸ—‚ï¸ Application Structure

demo_app/
â”‚
â”œâ”€â”€ Home.py
â”œâ”€â”€ Tokenization.py
â”œâ”€â”€ Embeddings.py
â”œâ”€â”€ Translation.py
â””â”€â”€ WordOrder.py

Running:

streamlit run Home.py


â¸»

ğŸ“„ Page 1 â€” Home / Overview

Purpose

Introduce concepts in plain English:
	â€¢	What is NLP?
	â€¢	What is machine translation?
	â€¢	Why are tokens, embeddings, and context important?

Core Elements
	â€¢	Simple markdown explaining the demo.
	â€¢	Navigation instructions.
	â€¢	No API calls.

Implementation Notes

Provide a conceptual graphic (ASCII optional):

TEXT â†’ TOKENS â†’ VECTORS â†’ TRANSFORMER â†’ TRANSLATION


â¸»

ğŸ“„ Page 2 â€” Tokenization Playground

Goal

Show users how words are broken into subword tokens and then mapped to token IDs.

Requirements
	â€¢	tiktoken for tokenizing.
	â€¢	Visual color blocks for each token.
	â€¢	Step-by-step UX.

User Experience Flow
	1.	User enters a word or short sentence.
	2.	They click â€œTokenizeâ€.
	3.	Show:
	â€¢	Token pieces
	â€¢	Token IDs
	â€¢	Total number of tokens
	4.	Step 2 button (optional):
	â€¢	â€œShow how this affects cost / model processingâ€

Key Code Concepts

import tiktoken

enc = tiktoken.get_encoding("cl100k_base")
tokens = enc.encode(user_input)
pieces = enc.encode(user_input, allowed_special=set(), disallowed_special=())


â¸»

ğŸ“„ Page 3 â€” Embedding Similarity Explorer

Goal

Show users how models turn text into vectors, and how cosine similarity measures meaning.

Requirements
	â€¢	OpenAI embeddings API
	â€¢	Numpy for vector math
	â€¢	Simple bar chart for similarity score

User Experience Flow
	1.	User enters Sentence A.
	2.	User enters Sentence B.
	3.	Click â€œCompute Meaning Similarityâ€.
	4.	App shows:
	â€¢	A percent similarity
	â€¢	A simple color-coded interpretation
	â€¢	Optional: vector length / shape info
	5.	Optional step:
	â€¢	â€œShow embedding vectorâ€ (collapsed by default)

Similarity Calculation

import numpy as np

def cosine(a, b):
    return np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b))


â¸»

ğŸ“„ Page 4 â€” Translation Sandbox

Goal

Demonstrate MT performance, ambiguity, and context sensitivity.

Requirements
	â€¢	GPT model capable of multilingual translation
	â€¢	Step-by-step interface to show incremental improvement with added context

User Experience Flow

Step 1 â€” Basic Translation
	1.	User enters text.
	2.	Selects target language.
	3.	Click Translate.
	4.	Details shown:
	â€¢	Translation
	â€¢	Confidence explanation
	â€¢	Whether sentence is ambiguous

Step 2 â€” Add Context
	5.	User enters additional context (â€œHe was an astronomerâ€).
	6.	Click Re-translate with context.
	7.	Show difference side-by-side.

Example Prompt

Translate this sentence into Spanish. Only provide the translation.
Sentence: {text}


â¸»

ğŸ“„ Page 5 â€” Word Order & Transformer Behavior

Goal

Show how word order affects meaning and translation quality.

Requirements
	â€¢	Same translation model
	â€¢	Preloaded examples

User Experience Flow
	1.	User clicks a button:
	â€¢	Example 1: Normal word order
	â€¢	Example 2: Reordered clauses
	â€¢	Example 3: Highly scrambled sentence
	2.	App displays:
	â€¢	Original sentence
	â€¢	Translation
	â€¢	Short explanation why translation drifted

Educational Outcomes
	â€¢	Positional encoding concepts
	â€¢	Attention robustness and its limits
	â€¢	Why transformers outperform older RNN/LSTM systems

â¸»

ğŸ§ª Core Demo Code (Modular Snippets)

Below are reusable abstractions youâ€™ll implement once and share across pages:

Embedding Function

from openai import OpenAI
client = OpenAI()

def embed(text):
    return client.embeddings.create(
        model="text-embedding-3-small",
        input=text
    ).data[0].embedding

Translation Function

def translate(text, target_lang):
    prompt = f"Translate this into {target_lang}. Only return the translation: {text}"
    response = client.chat.completions.create(
        model="gpt-4o-mini",
        messages=[{"role": "user", "content": prompt}]
    )
    return response.choices[0].message.content


â¸»

ğŸ¨ UI/UX Principles for Non-Technical Audiences
	â€¢	Use big buttons, clear labels.
	â€¢	Hide complexity behind expandable sections.
	â€¢	Use color-coded outputs:
	â€¢	Green = similar meaning
	â€¢	Yellow = moderate similarity
	â€¢	Red = different
	â€¢	Include one-sentence explanations under every result.
	â€¢	Always show the workflow:
Step 1 â†’ Step 2 â†’ Step 3

â¸»

ğŸ“‘ Deployment Options

Local

streamlit run Home.py

Cloud Options
	â€¢	Streamlit Cloud
	â€¢	GitHub Codespaces
	â€¢	HuggingFace Spaces
	â€¢	Docker container on a cloud VM

Use OpenAI API keys stored in environment variables only.

â¸»

ğŸ”š Conclusion

This multi-page Streamlit app provides a simple, visually engaging, and non-technical-friendly platform for demonstrating the key concepts behind modern NLP and machine translation.

By structuring each page as a guided, step-by-step scenario, you ensure users not only see the outputs, but actually understand how machine intelligence processes and transforms language.

â¸»

If youâ€™d like, I can now generate:

âœ… Full working Streamlit app code (all pages)
âœ… Matching slide deck for your webinar
âœ… A one-page cheat sheet for attendees

Just tell me what you want next!
